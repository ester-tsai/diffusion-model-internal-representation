<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>DSC180B Final Project</title>
    <!-- Favicon-->
    <link rel="icon" type="image/x-icon" href="assets/favicon.png" />
    <!-- Font Awesome icons (free version)-->
    <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
</head>

<body id="page-top">
    <!-- Navigation-->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
        <div class="container">
            <a class="navbar-brand" href="#page-top"> DSC180B B11-1 </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
                aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                Menu
                <i class="fas fa-bars ms-1"></i>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav text-uppercase ms-auto py-4 py-lg-0">
                    <li class="nav-item"><a class="nav-link" href="#services">Background</a></li>
                    <li class="nav-item"><a class="nav-link" href="#portfolio">Data</a></li>
                    <li class="nav-item"><a class="nav-link" href="#about">Methods</a></li>
                    <li class="nav-item"><a class="nav-link" href="#results">Results</a></li>
                    <li class="nav-item"><a class="nav-link" href="#discussion">Discussion</a></li>
                    <li class="nav-item"><a class="nav-link" href="#material">Project Material</a></li>
                    <li class="nav-item"><a class="nav-link" href="#team">Team</a></li>
                </ul>
            </div>
        </div>
    </nav>
    <!-- Masthead-->
    <header class="masthead">
        <div class="container">
            <div class="masthead-subheading">Karina Chen, Atharva Kulkarni, Ester Tsai, Zelong Wang</div>
            <div class="masthead-heading text-uppercase">From Pixels to Pictures:</br>Understanding the Internal Representations of</br>Latent Diffusion Models</div>
            <a class="btn btn-primary btn-xl text-uppercase" href="#services">Tell Me More</a>
        </div>
    </header>
    <!-- Services-->
    <section class="page-section" id="services">
        <div class="container">
            <div class="text-center">
                <h2 class="section-heading text-uppercase">Background</h2>
<!--                 <h3 class="section-subheading text-muted">How did this project come to be?</h3> -->
            </div>
            <div class="row text-center">
                <div class="col-md-4">
<!--                     <span class="fa-stack fa-4x">
                        <i class="fas fa-circle fa-stack-2x text-primary"></i>
                        <i class="fa-solid fa-school fa-stack-1x fa-inverse"></i>
                    </span> -->
                    <h4 class="my-3">Diffusion Model</h4>
                    <p class="text-muted">
                        Image generators like Dall-E, Google's Imagen, Stable Diffusion, and Midjourney use diffusion models to perform formerly manual tasks like image creation, denoising, inpainting, and outpainting. 
                        </br></br>The diffusion method consists of a forward diffusion process and a reverse process. The goal of the model is to iteratively reverse the diffusion by predicting the Gaussian noise added at each time step.

                    </p>
                </div>
                <div class="col-md-4">
<!--                     <span class="fa-stack fa-4x">
                        <i class="fas fa-circle fa-stack-2x text-primary"></i>
                        <i class="fas fa-laptop fa-stack-1x fa-inverse"></i>
                    </span> -->
                    <h4 class="my-3">Stable Diffusion</h4>
                    <p class="text-muted">
                        Stable Diffusion is an open-source diffusion model that generates images from text prompts. It consists of 2 stages:
                        <ol class="text-muted">
                          <li>Latent Diffusion Model (LDM): The LDM learns to predict and remove noise in the latent space by reversing a forward diffusion process. </li>
                          <li>Variational Autoencoder (VAE): The VAE converts data between latent and image space. </li>
                        </ol>
                    </p>
                </div>
                <div class="col-md-4">
<!--                     <span class="fa-stack fa-4x">
                        <i class="fas fa-circle fa-stack-2x text-primary"></i>
                        <i class="fa-brands fa-twitter fa-stack-1x fa-inverse"></i>
                    </span> -->
                    <h4 class="my-3">Problem Statement</h4>
                    <p class="text-muted">
                        It is a mystery how an LDM transforms a phrase like "car on the road" into a picture. Does the LDM memorize superficial correlations between pixel values and words? 
                        Or does it learn an underlying model of objects (e.g. cars, roads) and how they are typically positioned?
                        </br></br>So we ask: Does an LDM create an internal 3D representation of the object it portrays in 2D? 
                        </br>Additionally we ask: At what time step does an image classifier correctly detect the object?
                    </p>
                </div>
            </div>
        </div>
    </section>
    <!-- Portfolio Grid-->
    <section class="page-section bg-light" id="portfolio">
        <div class="container">
            <div class="text-center">
                <h2 class="section-heading text-uppercase">Data</h2>
            </div>
            <div>
                <h3> LDM Generated Image Dataset </h3>
                <p class='text-muted'>
                    Our diffusion image dataset consists of 617 images (512 pixels x 512 pixels) generated using Stable Diffusion v1.4. We have a CSV file that contains the prompt index, text prompt, and seed for each image. For example, the image with the prompt index 5246271, the text prompt "ZIGGY - EASY ARMCHAIR", and the seed 64140790 generated this 512 by 512 image.
                    <br>
                </p>
                <div class='text-center'>
                     <img src='assets/img/data/dataset.png' height=600 width=600 />
                     <figcaption>(top left) 512 x 512 image generated by Stable Diffusion v1.4. <br>
                        (top right) Salient object detection mask generated by TRACER. <br>
                        (bottom left) Depth map generated by MiDaS. <br> 
                        (bottom right) Shading and illumination map generated by Intrinsic.<br></figcaption>

                        <br>
                </div>

                <h3> TRACER/MiDaS/Intrinsic Generated Image Label </h3>
                <p class='text-muted'>

                    For salient object detection, we apply the salient object tracing model TRACER to generate a mask for each image. The masks are black and white, where white indicates the salient object, or foreground, and black indicates the background. 

                    <br>
                <p class='text-muted'>

                    For depth labels, we apply the pre-trained MiDaS model to the diffusion images to estimate their relative inverse depth maps. 

                    <br>

                <p class='text-muted'>

                    For shading labels, we apply the pre-trained Intrinsic model to the diffusion images to generate highly accurate intrinsic decompositions and estimate the shading maps.

                    <br>
                
            </div>
        </div>
    </section>
    <!-- About-->
    <section class="page-section" id="about">
        <div class="container">
            <div class="text-center">
                <h2 class="section-heading text-uppercase">Methods</h2>
                <h3 class="section-subheading text-muted">Timeline of development for the two GPT-3 powered models.</h3>
            </div>
            <ul class="timeline">
                <li>
                    <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/openai.png"
                            alt="..." /></div>
                    <div class="timeline-panel">
                        <div class="timeline-heading">
                            <h3>Model Selection</h3>
                            <h5 class="subheading">Choosing the Right GPT-3 Submodel</h5>
                        </div>
                        <div class="timeline-body">
                            <p class="text-muted">GPT-3 has 4 powerful models under its hood, but <code> davinci </code>
                                was our selection due to its higher capacity for understanding specific instruction.
                                Furthermore, its training data ends in October 2021, nearly 2 years after every other
                                model choice.
                            </p>
                        </div>
                    </div>
                </li>
                <li class="timeline-inverted">
                    <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/writing.png"
                            alt="..." /></div>
                    <div class="timeline-panel">
                        <div class="timeline-heading">
                            <h3>Initial Prompting</h3>
                            <h5 class="subheading">Starting the Process</h5>
                        </div>
                        <div class="timeline-body">

                            <p class="text-muted">
                                Initially, both prompts started with very simplistic formats. No in-context learning was
                                used, and fairly simplistic definitions of terms like 'relevance', 'positive',
                                'neutral', and 'negative' were used. Because each Tweet required its own API call to the
                                OpenAI GPT-3 API, the prompts were run on samples of 100 Tweets at a time rather than
                                the whole dataset.
                            </p>

                        </div>
                    </div>
                </li>
                <li>
                    <div class="timeline-image"><img class="rounded-circle img-fluid"
                            src="assets/img/about/handyman.png" alt="..." /></div>
                    <div class="timeline-panel">
                        <div class="timeline-heading">
                            <h3>Prompt Engineering</h3>
                            <h5 class="subheading">Improving Classification</h5>
                        </div>
                        <div class="timeline-body">
                            <p class="text-muted">
                                In order to improve the results from the model, further prompt tuning was required. Both
                                prompts pursued 'few-shot' learning, where the prompt itself provides example inputs,
                                outputs, and reasonings. These included randomly selected Tweets as well as 'pain-point'
                                examples that highlighted where the model consistently struggled.
                            </p>
                        </div>
                    </div>
                </li>
                <li class="timeline-inverted">
                    <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/sklearn.png"
                            alt="..." /></div>
                    <div class="timeline-panel">
                        <div class="timeline-heading">
                            <h3>Comparing to Quarter 1 Results</h3>
                            <h5 class="subheading">Evaluate Applicability of GPT-3 Models</h5>
                            <p class="text-muted">
                                To assess if GPT-3 improved classification performance from the team's results in
                                quarter 1, we compared the GPT-3's performance in classifying Tweet relevance with the
                                Naive Bayes Classifer from quarter 1 and compared the GPT-3's performance in evalutaing
                                sentiment with a Random Forest Classifer.
                            </p>
                        </div>
                        <div class="timeline-body">
                            <p class="text-muted"></p>
                        </div>
                    </div>
                </li>
                <li>
                    <div class="timeline-image"><img class="rounded-circle img-fluid" src="assets/img/about/twitter.png"
                            alt="..." /></div>
                    <div class="timeline-panel">
                        <div class="timeline-heading">
                            <h3>Evaluate and Wrapping Up</h3>
                            <h5 class="subheading"> Into the Future </h5>
                        </div>
                        <div class="timeline-body">
                            <p class="text-muted">

                                After running through prompt engineering, sampling, and evaluating several times, the
                                last step of the project was to communicate our findings and results with our mentors
                                from the China Data Lab, and deciding what role GPT-3 can have in the future of the
                                'Congress Tweets' project.

                            </p>
                        </div>
                    </div>
                </li>
            </ul>
        </div>
    </section>

    <!-- Results-->
    <section class="page-section bg-light" id="results">
        <div class="container">
            <div class="text-center">
                <h2 class="section-heading text-uppercase">Results</h2>
                <!-- <h3 class="section-subheading text-muted">Probing the LDM</h3> -->
            </div>
            <div>
                <h3> Probing the LDM </h3>
                
                <p class='text-muted'>

                    Using intermediate activations of noisy input images, linear probes can accurately predict
                    the foreground, depth, and shading. All three properties emerge early in the denoising process
                    (around step 3 out of 15), suggesting that the spatial layout of the generated image is determined
                    at the very beginning of the generative process.

                    <br>
                    <table class='text-muted'>
                        <tr>
                          <th>Foreground segmentation Dice coefficient</th>
                          <td>0.85</th>
                        </tr>
                        <tr>
                          <th>Depth Estimation MSE</td>
                          <td>0.47</td>
                        </tr>
                        <tr>
                          <th>Shading estimation MSE</td>
                          <td>?</td>
                        </tr>
                    </table>
                    <br>
                <div class='text-center'> <img src='assets/img/internal_repr/car_all.png' height=500 alt="diffusion, mask, depth, shading for car image"/> </div>

                </p>
            </div>
            <br>
            <div class="row">
                <h3> Intervening the LDM </h3>
                <!-- </tr>
                </table> -->
                <!-- <img src="assets/img/result/cm_normalized.png" class="'cm_plot" alt="..." /> -->
                <p class="text-muted">
                    Foreground mask has a causal role in image generation. Without changing the prompt, input latent
                    vector, and model weights, we can modify the scene layout of generated image by editing the
                    foreground mask (Y. Chen et  al.)

                    <!-- <br> -->
                    <div class='text-center'><img src="assets/img/internal_repr/intervention.png" width=900 alt="intervention"> </div>

                </p>
            </div>
        </div>
    </section>

    <!-- Discussion -->
    <section class="page-section" id="discussion">
        <div class="container">
            <div class="text-center">
                <h2 class="section-heading text-uppercase">Discussion</h2>
                <h3 class="section-subheading text-muted">What did we learn in this project?</h3>
            </div>
            <div class="row text-center">
                <div class="col-md-4">

                    <span class="fa-stack fa-4x">
                        <i class="fas fa-circle fa-stack-2x text-primary"></i>
                        <i class="fas fa-screwdriver-wrench fa-stack-1x fa-inverse"></i>
                    </span>

                    <h4 class="my-3">Our Project</h4>
                    <p class="text-muted">

                        The application of LLMs to this particular topic generated measures that fell short of our
                        expectations, and of our Quarter 1 results. Despite continuous engineering of the prompt, we
                        were not able to match our original statistics in classifying relevance nor achieve high
                        accuracy in classifying sentiment; however, the process of using an LLM like GPT-3 revealed
                        clearly that these tools definitely have their place in this field.

                        In conversing with the UCSD China Data Lab over the course of the last 10 weeks, our work has
                        been helpful in determining whether they will move forward with using LLMs throughout the future
                        stages of their Twitter analysis projects.

                    </p>
                </div>

                <div class="col-md-4">

                    <span class="fa-stack fa-4x">
                        <i class="fas fa-circle fa-stack-2x text-primary"></i>
                        <i class="fas fa-wand-magic-sparkles fa-stack-1x fa-inverse"></i>
                    </span>

                    <h4 class="my-3">Limitations & Future </h4>
                    <p class="text-muted">

                        Looking at the overall performance of the GPT-3 language models, and even at the supervised ML
                        pathways from earlier, it's easy to see that this is a difficult task no matter what tools we
                        use. Human interpretation of text is so influenced by preexisting biases, contexts, and other
                        factors that cannot be modeled, and the strange Internet-affected language of Twitter only
                        contributes to this further.

                        Because of LLMs' ability to comprehend text in its own context, outside the purview of 'trainign
                        data', it is worth considering shifting away from a simple classification & sentiment analysis,
                        and to utilize the full power of these models for deeper textual analysis.

                    </p>
                </div>

                <div class="col-md-4">

                    <span class="fa-stack fa-4x">
                        <i class="fas fa-circle fa-stack-2x text-primary"></i>
                        <i class="fas fa-comments fa-stack-1x fa-inverse"></i>
                    </span>

                    <h4 class="my-3">The Models</h4>
                    <p class="text-muted">

                        Large Language Models are undoubtedly the future of language modeling and analysis. Their
                        incredible power, ease-of-use, and high quality outputs put them far ahead of any other
                        traditional NLP methodology. However, that does not mean simply tossing out what's been done
                        before and trusting GPT-3 to always get the solution. As our project shows, GPT-3 is not always
                        ready to bridge the gap resulting from natural differences in human interpretation and context.

                        Subject matter expertise and domain knowledge are and will remain absolutely key to getting the
                        best out of these models.

                    </p>
                </div>
            </div>
        </div>
    </section>

    <section class="page-section bg-light" id="material">
        <div class="container">
            <div class="text-center">
                <h2 class="section-heading text-uppercase">Project Material</h2>
                <h3 class="section-subheading text-muted">Our Deliverables</h3>
            </div>
            <div class="row text-center">

                <div class='flex-container'>
                    <div class='flex-item'>
                        <h4>Report</h4>
                        <p class='text-muted'> Our published paper with more information.</p>
                        <span class="fa-stack fa-4x">
                            <a href="assets/deliverables/report.pdf">
                                <i class="fas fa-circle fa-stack-2x text-primary"></i>
                                <i class="fas fa-copy fa-stack-1x fa-inverse"></i></a>
                        </span>
                    </div>

                    <div class='flex-item'>

                        <h4>Poster</h4>
                        <p class='text-muted'>Our showcase poster for presentation.</p>
                        <span class="fa-stack fa-4x">
                            <a href="assets/deliverables/poster.png">
                                <i class="fas fa-circle fa-stack-2x text-primary"></i>
                                <i class="fas fa-microphone fa-stack-1x fa-inverse"></i></a>
                        </span>
                    </div>
                </div>








            </div>

    </section>

    <!-- Team-->
    <section class="page-section" id="team">
        <div class="container">
            <div class="text-center">
                <h2 class="section-heading text-uppercase">Our Team</h2>
                <h3 class="section-subheading text-muted">Meet our Team!</h3>
            </div>
            <div class='flex-container'>
                <div class="flex-item">
                    <div class="team-member">
                        <img class="mx-auto rounded-circle" src="assets/img/team/ester.jpg" alt="..." />
                        <h4>Ester Tsai</h4>
                        <p class="text-muted">UCSD '24, Data Science minoring in Mathematics</p>
                        <a class="btn btn-dark btn-social mx-2" href="https://github.com/ester-tsai"
                            aria-label="Parveen Anand Facebook Profile"><i class="fab fa-github"></i></a>
                        <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/ester-tsai"
                            aria-label="Parveen Anand LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                    </div>
                </div>
                <div class="flex-item">
                    <div class="team-member">
                        <img class="mx-auto rounded-circle" src="assets/img/team/annie.jpg" alt="..." />
                        <h4>Annie Fan</h4>
                        <p class="text-muted">UCSD '23, Data Science & Cognitive Science</p>
                        <a class="btn btn-dark btn-social mx-2" href="https://www.linkedin.com/in/chunzhi-fan/"
                            aria-label="Diana Petersen LinkedIn Profile"><i class="fab fa-linkedin-in"></i></a>
                    </div>
                </div>
            </div>
            <div class='flex-container'>
                <div class="flex-item">
                    <div class="team-member">
                        <img class="mx-auto rounded-circle" src="assets/img/team/roberts.jpeg" alt="..." />
                        <h4>Dr. Margaret Roberts</h4>
                        <p class="text-muted">Project Mentor</p>
                    </div>
                </div>
                <div class="flex-item">
                    <div class="team-member">
                        <img class="mx-auto rounded-circle" src="assets/img/team/young.png" alt="..." />
                        <h4>Dr. Young Yang</h4>
                        <p class="text-muted">Advisor from China Data Lab</p>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Footer-->
    <footer class="footer py-4 bg-light">
        <div class="container">
            <div class="row align-items-center">
                <div class="col-lg-4 text-lg-start">Copyright &copy; Karina Chen, Atharva Kulkarni, Ester Tsai, Zelong Wang 2024</div>
                <div class="col-lg-4 my-3 my-lg-0">

                    <script>
                        function about() {
                            alert(
                                'This website was made as a public-facing accompaniment to the work done by Karina Chen, Atharva Kulkarni, Ester Tsai, and Zelong Wang for the DSC180B course at UC San Diego. The website template design is borrowed from Gokul Prasad and Annie Fan. You can see the codebase for the work represented here by clicking on the GitHub icon at the bottom of the page! Thank you for visiting. '
                            );
                        }

                    </script>

                    <a class="btn btn-dark btn-social mx-2" href="https://github.com/gprasad125/dsc180b"
                        aria-label="Github"><i class="fab fa-github"></i></a>
                </div>
                <div class="col-lg-4 text-lg-end">
                    <a class="link-dark text-decoration-none me-3" href="#!" onclick="about()">About This Site</a>
                </div>
            </div>
        </div>
    </footer>
    <!-- Portfolio Modals-->
    <!-- Portfolio item 1 modal popup-->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-bs-dismiss="modal"><img src="assets/img/close-icon.svg"
                        alt="Close modal" /></div>
                <div class="container">
                    <div class="row justify-content-center">
                        <div class="col-lg-8">
                            <div class="modal-body">
                                <!-- Project details-->
                                <h2 class="text-uppercase">Relevance Distribution</h2>
                                <img class="img-fluid d-block mx-auto" src="assets/img/eda/relevance.png" alt="..." />
                                <p class="text-muted">
                                    The figure shows the distribution of relevant and irrelevant Tweets about China in
                                    the original dataset. The number of 'Relevant' tweets (demarcated 'True') is over
                                    twice the number of 'Irrelevant' Tweets, reflecting a class imbalance.
                                </p>
                                <button class="btn btn-primary btn-xl text-uppercase" data-bs-dismiss="modal"
                                    type="button">
                                    <i class="fas fa-xmark me-1"></i>
                                    Close
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio item 2 modal popup-->
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-bs-dismiss="modal"><img src="assets/img/close-icon.svg"
                        alt="Close modal" /></div>
                <div class="container">
                    <div class="row justify-content-center">
                        <div class="col-lg-8">
                            <div class="modal-body">
                                <!-- Project details-->
                                <h2 class="text-uppercase">Sentiment Distribution</h2>
                                <img class="img-fluid d-block mx-auto" src="assets/img/eda/sentiment.png" alt="..." />
                                <p class="text-muted">
                                    The figure shows the distribution of sentiment scores toward China in the original
                                    dataset. The sentiment scores are in range from 1 to 5 (1 = very negative, 3 =
                                    neutral, 5 = very positive). Tweets with sentiment score 0 and 6 are outliers. We
                                    can see that negative Tweets, scoring < 3 are represented far more than Tweets that
                                        score more positive. </p>
                                        <button class="btn btn-primary btn-xl text-uppercase" data-bs-dismiss="modal"
                                            type="button">
                                            <i class="fas fa-xmark me-1"></i>
                                            Close
                                        </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio item 3 modal popup-->
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-bs-dismiss="modal"><img src="assets/img/close-icon.svg"
                        alt="Close modal" /></div>
                <div class="container">
                    <div class="row justify-content-center">
                        <div class="col-lg-8">
                            <div class="modal-body">
                                <!-- Project details-->
                                <h2 class="text-uppercase">Sentiment Over Time</h2>
                                <img class="img-fluid d-block mx-auto" src="assets/img/eda/sentiment_by_time.png"
                                    alt="..." />
                                <p class="text-muted">
                                    This plot shows how the general sentiment towards China has varied across the time
                                    period in the data (2010-20) by party. Most notably, it is nearly consistently
                                    negative, with the Democrats in 2015 having the highest average sentiment still
                                    falling below 3.0. This also helps to explain why negative Tweets dominate the
                                    dataset.
                                </p>

                                <button class="btn btn-primary btn-xl text-uppercase" data-bs-dismiss="modal"
                                    type="button">
                                    <i class="fas fa-xmark me-1"></i>
                                    Close
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio item 4 modal popup-->
    <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-bs-dismiss="modal"><img src="assets/img/close-icon.svg"
                        alt="Close modal" /></div>
                <div class="container">
                    <div class="row justify-content-center">
                        <div class="col-lg-8">
                            <div class="modal-body">
                                <!-- Project details-->
                                <h2 class="text-uppercase">Tweet Count by State</h2>
                                <img class="img-fluid d-block mx-auto" src="assets/img/eda/TweetsByState.png"
                                    alt="..." />
                                <p class='text-muted'>
                                    Here, we see which U.S. states are most represented in our dataset. We note that
                                    among the most represented are the most populous -- Texas, California, Florida, etc.

                                    However, we also note that there is a strong Republican presence in the dataset,
                                    which also helps to explain the overwhelming negative Tweet count, as the Republican
                                    party has been consistently negative in their attiude towards China across the
                                    dataset's timeframe.
                                </p>
                                <button class="btn btn-primary btn-xl text-uppercase" data-bs-dismiss="modal"
                                    type="button">
                                    <i class="fas fa-xmark me-1"></i>
                                    Close
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio item 5 modal popup-->
    <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-bs-dismiss="modal"><img src="assets/img/close-icon.svg"
                        alt="Close modal" /></div>
                <div class="container">
                    <div class="row justify-content-center">
                        <div class="col-lg-8">
                            <div class="modal-body">
                                <!-- Project details-->
                                <h2 class="text-uppercase">Project Name</h2>
                                <p class="item-intro text-muted">Lorem ipsum dolor sit amet consectetur.</p>
                                <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/5.jpg" alt="..." />
                                <p>Use this area to describe your project. Lorem ipsum dolor sit amet, consectetur
                                    adipisicing elit. Est blanditiis dolorem culpa incidunt minus dignissimos deserunt
                                    repellat aperiam quasi sunt officia expedita beatae cupiditate, maiores repudiandae,
                                    nostrum, reiciendis facere nemo!</p>
                                <button class="btn btn-primary btn-xl text-uppercase" data-bs-dismiss="modal"
                                    type="button">
                                    <i class="fas fa-xmark me-1"></i>
                                    Close
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio item 6 modal popup-->
    <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-bs-dismiss="modal"><img src="assets/img/close-icon.svg"
                        alt="Close modal" /></div>
                <div class="container">
                    <div class="row justify-content-center">
                        <div class="col-lg-8">
                            <div class="modal-body">
                                <!-- Project details-->
                                <h2 class="text-uppercase">Project Name</h2>
                                <p class="item-intro text-muted">Lorem ipsum dolor sit amet consectetur.</p>
                                <img class="img-fluid d-block mx-auto" src="assets/img/portfolio/6.jpg" alt="..." />
                                <p>Use this area to describe your project. Lorem ipsum dolor sit amet, consectetur
                                    adipisicing elit. Est blanditiis dolorem culpa incidunt minus dignissimos deserunt
                                    repellat aperiam quasi sunt officia expedita beatae cupiditate, maiores repudiandae,
                                    nostrum, reiciendis facere nemo!</p>
                                <ul class="list-inline">
                                    <li>
                                        <strong>Client:</strong>
                                        Window
                                    </li>
                                    <li>
                                        <strong>Category:</strong>
                                        Photography
                                    </li>
                                </ul>
                                <button class="btn btn-primary btn-xl text-uppercase" data-bs-dismiss="modal"
                                    type="button">
                                    <i class="fas fa-xmark me-1"></i>
                                    Close Project
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
    <!-- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-->
    <!-- * *                               SB Forms JS                               * *-->
    <!-- * * Activate your form at https://startbootstrap.com/solution/contact-forms * *-->
    <!-- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-->
    <script src="https://cdn.startbootstrap.com/sb-forms-latest.js"></script>
</body>

</html>
